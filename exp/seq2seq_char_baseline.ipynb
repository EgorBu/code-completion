{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seq2seq_base\n",
    "import simple_char_fe as simple_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 150\n",
    "SNIPPET_LEN = 40\n",
    "folder = \"/usr/local/lib/python3.5/dist-packages/\"\n",
    "\n",
    "\n",
    "# func to estimate number of samples from number of lines in files\n",
    "def n_samples(n_lines):\n",
    "    return sqrt(n_lines)\n",
    "\n",
    "simple_fe.stat(folder, estimator_n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "feature_extraction_pipe = simple_fe.feature_extraction_pipe\n",
    "[before_vec, after_vec], snippet_vec, char_id = feature_extraction_pipe(\n",
    "    folder_loc=folder, max_len=MAX_LEN, snippet_len=SNIPPET_LEN, n_lines=10,\n",
    "    text_to_ind_vec=True, estimator_n_samples=n_samples,\n",
    "    token_ind=dict((ch, i + 1) for i, ch in enumerate(string.printable)))\n",
    "\n",
    "snippet_in = snippet_vec[:,:-1]\n",
    "snippet_target = snippet_vec[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "res = seq2seq_base.prepare_seq2seq_model(token2ind=char_id,\n",
    "                                         encoder_seq_len=MAX_LEN,\n",
    "                                         decoder_seq_len=SNIPPET_LEN)\n",
    "train_model, decode_sequence, ind2token = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "train_model.fit([before_vec, snippet_in],\n",
    "                np.expand_dims(snippet_target, axis=-1),\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inference step for several samples\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = before_vec[seq_index: seq_index + 1]\n",
    "    input_sent = \"\".join([ind2token.get(ind, \"\")\n",
    "                          for ind in input_seq[0]]).strip()\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input sentence:', input_sent)\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}