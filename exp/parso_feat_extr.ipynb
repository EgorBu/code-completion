{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from parso import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(folder):\n",
    "    folder_ = deepcopy(folder)\n",
    "    if not folder_.endswith(\"**/*.py\"):\n",
    "        if not folder_.endswith(\"/\"):\n",
    "            folder_ += \"/\"\n",
    "        folder_ += \"**/*.py\"\n",
    "    return folder_\n",
    "\n",
    "\n",
    "def get_token_ind(node, token2ind):\n",
    "    if node == \"push\" or node == \"pop\":\n",
    "        return token2ind.setdefault(node, len(token2ind))\n",
    "    elif \"keyword\" == node.type or \"operator\" == node.type:\n",
    "        # keywords: \"for\", \"while\", \"if\", etc.\n",
    "        # operators: \":\", \",\", \"+=\", etc.\n",
    "        return token2ind.setdefault(node.type + \"_\" + node.value, len(token2ind))\n",
    "    else:\n",
    "        return token2ind.setdefault(node.type, len(token2ind))\n",
    "\n",
    "\n",
    "def _file_features(root, token2ind):\n",
    "    yield get_token_ind(root, token2ind)\n",
    "    \n",
    "    if hasattr(root, \"children\"):\n",
    "        yield get_token_ind(\"push\", token2ind)\n",
    "        for ch in root.children:\n",
    "            yield from _file_features(ch, token2ind)\n",
    "        yield get_token_ind(\"pop\", token2ind)\n",
    "    \n",
    "\n",
    "def file_features(filename, token2ind):\n",
    "    with open(filename, errors=\"ignore\") as f:\n",
    "        content = f.read()\n",
    "        parser = parse(content)\n",
    "        return list(_file_features(parser, token2ind))        \n",
    "\n",
    "    \n",
    "def feat_extraction_pipeline(folder):\n",
    "    folder_ = check_folder(folder)\n",
    "        \n",
    "    token2ind = {}\n",
    "    feat = []\n",
    "    \n",
    "    for i, filename in enumerate(glob.iglob(folder_, recursive=True)):\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(i + 1, len(token2ind), sep=\"\\t\\t\", end=\"\\r\")\n",
    "        feat.append(file_features(filename, token2ind))\n",
    "    print(i + 1, len(token2ind), sep=\"\\t\\t\")\n",
    "    return feat, token2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6604\t\t15439\n",
      "number of unique tokens: 154\n",
      "number of samples: 6604\n",
      "total number of tokens: 29814322\n",
      "avg number of tokens per file: 4514.585402786191\n"
     ]
    }
   ],
   "source": [
    "folder = \"/usr/local/lib/python3.5/dist-packages\"\n",
    "\n",
    "feat, token2ind = feat_extraction_pipeline(folder)\n",
    "\n",
    "print(\"number of unique tokens:\", len(token2ind))\n",
    "print(\"number of samples:\", len(feat))\n",
    "print(\"total number of tokens:\", sum(map(len, feat)))\n",
    "print(\"avg number of tokens per file:\", sum(map(len, feat)) / len(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file_input', 0),\n",
       " ('push', 1),\n",
       " ('simple_stmt', 2),\n",
       " ('string', 3),\n",
       " ('newline', 4),\n",
       " ('pop', 5),\n",
       " ('if_stmt', 6),\n",
       " ('keyword_if', 7),\n",
       " ('comparison', 8),\n",
       " ('name', 9),\n",
       " ('operator_==', 10),\n",
       " ('operator_:', 11),\n",
       " ('suite', 12),\n",
       " ('import_from', 13),\n",
       " ('keyword_from', 14),\n",
       " ('dotted_name', 15),\n",
       " ('operator_.', 16),\n",
       " ('keyword_import', 17),\n",
       " ('atom_expr', 18),\n",
       " ('trailer', 19),\n",
       " ('operator_(', 20),\n",
       " ('operator_)', 21),\n",
       " ('endmarker', 22),\n",
       " ('operator_*', 23),\n",
       " ('import_name', 24),\n",
       " ('expr_stmt', 25),\n",
       " ('operator_=', 26),\n",
       " ('import_as_name', 27),\n",
       " ('keyword_as', 28),\n",
       " ('try_stmt', 29),\n",
       " ('keyword_try', 30),\n",
       " ('except_clause', 31),\n",
       " ('keyword_except', 32),\n",
       " ('keyword_None', 33),\n",
       " ('atom', 34),\n",
       " ('operator_[', 35),\n",
       " ('testlist_comp', 36),\n",
       " ('operator_,', 37),\n",
       " ('operator_]', 38),\n",
       " ('subscript', 39),\n",
       " ('number', 40),\n",
       " ('keyword_else', 41),\n",
       " ('funcdef', 42),\n",
       " ('keyword_def', 43),\n",
       " ('parameters', 44),\n",
       " ('param', 45),\n",
       " ('arglist', 46),\n",
       " ('return_stmt', 47),\n",
       " ('keyword_return', 48),\n",
       " ('lambdef', 49),\n",
       " ('keyword_lambda', 50),\n",
       " ('arith_expr', 51),\n",
       " ('operator_+', 52),\n",
       " ('factor', 53),\n",
       " ('operator_-', 54),\n",
       " ('for_stmt', 55),\n",
       " ('keyword_for', 56),\n",
       " ('keyword_in', 57),\n",
       " ('keyword_continue', 58),\n",
       " ('comp_for', 59),\n",
       " ('exprlist', 60),\n",
       " ('classdef', 61),\n",
       " ('keyword_class', 62),\n",
       " ('keyword_pass', 63),\n",
       " ('argument', 64),\n",
       " ('comp_if', 65),\n",
       " ('comp_op', 66),\n",
       " ('keyword_not', 67),\n",
       " ('keyword_is', 68),\n",
       " ('decorated', 69),\n",
       " ('decorator', 70),\n",
       " ('operator_@', 71),\n",
       " ('keyword_elif', 72),\n",
       " ('raise_stmt', 73),\n",
       " ('keyword_raise', 74),\n",
       " ('term', 75),\n",
       " ('operator_%', 76),\n",
       " ('keyword_True', 77),\n",
       " ('keyword_False', 78),\n",
       " ('operator_{', 79),\n",
       " ('operator_}', 80),\n",
       " ('and_test', 81),\n",
       " ('keyword_and', 82),\n",
       " ('not_test', 83),\n",
       " ('del_stmt', 84),\n",
       " ('keyword_del', 85),\n",
       " ('operator_<', 86),\n",
       " ('operator_+=', 87),\n",
       " ('operator_>', 88),\n",
       " ('sliceop', 89),\n",
       " ('operator_**', 90),\n",
       " ('or_test', 91),\n",
       " ('keyword_or', 92),\n",
       " ('test', 93),\n",
       " ('testlist', 94),\n",
       " ('operator_>=', 95),\n",
       " ('while_stmt', 96),\n",
       " ('keyword_while', 97),\n",
       " ('keyword_finally', 98),\n",
       " ('operator_<=', 99),\n",
       " ('testlist_star_expr', 100),\n",
       " ('with_stmt', 101),\n",
       " ('keyword_with', 102),\n",
       " ('yield_expr', 103),\n",
       " ('keyword_yield', 104),\n",
       " ('operator_-=', 105),\n",
       " ('expr', 106),\n",
       " ('operator_|', 107),\n",
       " ('xor_expr', 108),\n",
       " ('operator_^', 109),\n",
       " ('and_expr', 110),\n",
       " ('operator_&', 111),\n",
       " ('with_item', 112),\n",
       " ('operator_!=', 113),\n",
       " ('keyword_break', 114),\n",
       " ('dictorsetmaker', 115),\n",
       " ('operator_|=', 116),\n",
       " ('operator_~', 117),\n",
       " ('shift_expr', 118),\n",
       " ('operator_<<', 119),\n",
       " ('operator_<<=', 120),\n",
       " ('operator_/', 121),\n",
       " ('dotted_as_name', 122),\n",
       " ('import_as_names', 123),\n",
       " ('assert_stmt', 124),\n",
       " ('keyword_assert', 125),\n",
       " ('subscriptlist', 126),\n",
       " ('global_stmt', 127),\n",
       " ('keyword_global', 128),\n",
       " ('dotted_as_names', 129),\n",
       " ('operator_>>=', 130),\n",
       " ('decorators', 131),\n",
       " ('operator_*=', 132),\n",
       " ('operator_%=', 133),\n",
       " ('operator_/=', 134),\n",
       " ('operator_...', 135),\n",
       " ('operator_//', 136),\n",
       " ('power', 137),\n",
       " ('operator_&=', 138),\n",
       " ('operator_//=', 139),\n",
       " ('operator_**=', 140),\n",
       " ('operator_>>', 141),\n",
       " ('operator_;', 142),\n",
       " ('operator_^=', 143),\n",
       " ('error_node', 144),\n",
       " ('typedargslist', 145),\n",
       " ('keyword_async', 146),\n",
       " ('error_leaf', 147),\n",
       " ('yield_arg', 148),\n",
       " ('operator_->', 149),\n",
       " ('tfpdef', 150),\n",
       " ('async_stmt', 151),\n",
       " ('async_funcdef', 152),\n",
       " ('keyword_await', 153)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(token2ind.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\n",
      "import pickle\n",
      "import numpy as np\n",
      "++++++++++ parser output\n",
      ": file_input\n",
      "-: push\n",
      "-: simple_stmt\n",
      "--: push\n",
      "--: import_name\n",
      "---: push\n",
      "---: keyword \"import\"\n",
      "---: name \"pickle\"\n",
      "--: pop\n",
      "--: newline \"\n",
      "\"\n",
      "-: pop\n",
      "-: import_name\n",
      "--: push\n",
      "--: keyword \"import\"\n",
      "--: dotted_as_name\n",
      "---: push\n",
      "---: name \"numpy\"\n",
      "---: keyword \"as\"\n",
      "---: name \"np\"\n",
      "--: pop\n",
      "-: pop\n",
      "-: endmarker \"\"\n",
      ": pop\n",
      "\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\n",
      "\n",
      "folder = \"some_folder\"\n",
      "\n",
      "with open(folder, \"wb\") as f:\n",
      "    pickle.dump((feat, token2ind), f\n",
      "++++++++++ parser output\n",
      ": file_input\n",
      "-: push\n",
      "-: simple_stmt\n",
      "--: push\n",
      "--: expr_stmt\n",
      "---: push\n",
      "---: name \"folder\"\n",
      "---: operator \"=\"\n",
      "---: string \"\"some_folder\"\"\n",
      "--: pop\n",
      "--: newline \"\n",
      "\"\n",
      "-: pop\n",
      "-: with_stmt\n",
      "--: push\n",
      "--: keyword \"with\"\n",
      "--: with_item\n",
      "---: push\n",
      "---: atom_expr\n",
      "----: push\n",
      "----: name \"open\"\n",
      "----: trailer\n",
      "-----: push\n",
      "-----: operator \"(\"\n",
      "-----: arglist\n",
      "------: push\n",
      "------: name \"folder\"\n",
      "------: operator \",\"\n",
      "------: string \"\"wb\"\"\n",
      "-----: pop\n",
      "-----: operator \")\"\n",
      "----: pop\n",
      "---: pop\n",
      "---: keyword \"as\"\n",
      "---: name \"f\"\n",
      "--: pop\n",
      "--: operator \":\"\n",
      "--: suite\n",
      "---: push\n",
      "---: newline \"\n",
      "\"\n",
      "---: error_node\n",
      "----: push\n",
      "----: name \"pickle\"\n",
      "----: trailer\n",
      "-----: push\n",
      "-----: operator \".\"\n",
      "-----: name \"dump\"\n",
      "----: pop\n",
      "----: operator \"(\"\n",
      "----: arglist\n",
      "-----: push\n",
      "-----: atom\n",
      "------: push\n",
      "------: operator \"(\"\n",
      "------: testlist_comp\n",
      "-------: push\n",
      "-------: name \"feat\"\n",
      "-------: operator \",\"\n",
      "-------: name \"token2ind\"\n",
      "------: pop\n",
      "------: operator \")\"\n",
      "-----: pop\n",
      "-----: operator \",\"\n",
      "-----: name \"f\"\n",
      "----: pop\n",
      "---: pop\n",
      "--: pop\n",
      "-: pop\n",
      "-: endmarker \"\"\n",
      ": pop\n",
      "\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\n",
      "\n",
      "some_var = 'asd'\n",
      "some_int = 5\n",
      "some_float = 5.\n",
      "some_bool = True\n",
      "++++++++++ parser output\n",
      ": file_input\n",
      "-: push\n",
      "-: simple_stmt\n",
      "--: push\n",
      "--: expr_stmt\n",
      "---: push\n",
      "---: name \"some_var\"\n",
      "---: operator \"=\"\n",
      "---: string \"'asd'\"\n",
      "--: pop\n",
      "--: newline \"\n",
      "\"\n",
      "-: pop\n",
      "-: simple_stmt\n",
      "--: push\n",
      "--: expr_stmt\n",
      "---: push\n",
      "---: name \"some_int\"\n",
      "---: operator \"=\"\n",
      "---: number \"5\"\n",
      "--: pop\n",
      "--: newline \"\n",
      "\"\n",
      "-: pop\n",
      "-: simple_stmt\n",
      "--: push\n",
      "--: expr_stmt\n",
      "---: push\n",
      "---: name \"some_float\"\n",
      "---: operator \"=\"\n",
      "---: number \"5.\"\n",
      "--: pop\n",
      "--: newline \"\n",
      "\"\n",
      "-: pop\n",
      "-: expr_stmt\n",
      "--: push\n",
      "--: name \"some_bool\"\n",
      "--: operator \"=\"\n",
      "--: keyword \"True\"\n",
      "-: pop\n",
      "-: endmarker \"\"\n",
      ": pop\n",
      "\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\n",
      "\n",
      "def a():\n",
      "    return 0\n",
      "++++++++++ parser output\n",
      ": file_input\n",
      "-: push\n",
      "-: funcdef\n",
      "--: push\n",
      "--: keyword \"def\"\n",
      "--: name \"a\"\n",
      "--: parameters\n",
      "---: push\n",
      "---: operator \"(\"\n",
      "---: operator \")\"\n",
      "--: pop\n",
      "--: operator \":\"\n",
      "--: suite\n",
      "---: push\n",
      "---: newline \"\n",
      "\"\n",
      "---: return_stmt\n",
      "----: push\n",
      "----: keyword \"return\"\n",
      "----: number \"0\"\n",
      "---: pop\n",
      "--: pop\n",
      "-: pop\n",
      "-: endmarker \"\"\n",
      ": pop\n",
      "\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\n",
      "[i for i in range(10)]\n",
      "++++++++++ parser output\n",
      ": file_input\n",
      "-: push\n",
      "-: atom\n",
      "--: push\n",
      "--: operator \"[\"\n",
      "--: testlist_comp\n",
      "---: push\n",
      "---: name \"i\"\n",
      "---: comp_for\n",
      "----: push\n",
      "----: keyword \"for\"\n",
      "----: name \"i\"\n",
      "----: keyword \"in\"\n",
      "----: atom_expr\n",
      "-----: push\n",
      "-----: name \"range\"\n",
      "-----: trailer\n",
      "------: push\n",
      "------: operator \"(\"\n",
      "------: number \"10\"\n",
      "------: operator \")\"\n",
      "-----: pop\n",
      "----: pop\n",
      "---: pop\n",
      "--: pop\n",
      "--: operator \"]\"\n",
      "-: pop\n",
      "-: endmarker \"\"\n",
      ": pop\n",
      "\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\\|/\n",
      "a = 5\n",
      "++++++++++ parser output\n",
      ": file_input\n",
      "-: push\n",
      "-: expr_stmt\n",
      "--: push\n",
      "--: name \"a\"\n",
      "--: operator \"=\"\n",
      "--: number \"5\"\n",
      "-: pop\n",
      "-: endmarker \"\"\n",
      ": pop\n"
     ]
    }
   ],
   "source": [
    "# some visualization functionality\n",
    "def print_structure(root, offset=\"\"):\n",
    "    to_print = offset + \": \" + root.type\n",
    "    if hasattr(root, \"value\"):\n",
    "        to_print += \" \\\"\" + root.value +\"\\\"\"\n",
    "    print(to_print)        \n",
    "    \n",
    "    if hasattr(root, \"children\"):\n",
    "        offset += \"-\"\n",
    "        print(offset + \": \" + \"push\")\n",
    "        for ch in root.children:\n",
    "            print_structure(ch, offset)\n",
    "        offset = offset[:-1]\n",
    "        print(offset + \": \" + \"pop\")\n",
    "        \n",
    "\n",
    "codes = [\"\"\"import pickle\n",
    "import numpy as np\"\"\", \"\"\"\n",
    "folder = \"some_folder\"\n",
    "\n",
    "with open(folder, \"wb\") as f:\n",
    "    pickle.dump((feat, token2ind), f\"\"\", \"\"\"\n",
    "some_var = 'asd'\n",
    "some_int = 5\n",
    "some_float = 5.\n",
    "some_bool = True\"\"\", \"\"\"\n",
    "def a():\n",
    "    return 0\"\"\", \"\"\"[i for i in range(10)]\"\"\", \"a = 5\"]\n",
    "\n",
    "parsers = [parse(code) for code in codes]\n",
    "\n",
    "for c, p in zip(codes, parsers):\n",
    "    print(\"\\|/\" * 10)\n",
    "    print(c)\n",
    "    print(\"+\" * 10, \"parser output\")\n",
    "    print_structure(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_features = \"location_to_save_features\"\n",
    "with open(save_features, \"wb\") as f:\n",
    "    pickle.dump((feat, token2ind), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}