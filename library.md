# Papers


### Top-down Tree Long Short-Term Memory Networks
https://arxiv.org/abs/1503.00075

Details:

Thoughts:
### When Are Tree Structures Necessary for Deep Learning of Representations?

https://nlp.stanford.edu/pubs/emnlp2015_2_jiwei.pdf

Details:

Thoughts:
### Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks
http://www.aclweb.org/anthology/P15-1150

Details:

Thoughts:
### arxiv-sanity: similar to "Top-down Tree Long Short-Term Memory Networks"
http://arxiv-sanity.com/1503.00075

Details:

Thoughts:
### Recurrent Memory Networks for Language Modeling: in Sentence Completion Challenge, for which it is essential to capture sentence coherence, our RMN obtains 69.2% accuracy, surpassing the previous state-of-the-art by a large margin.
https://arxiv.org/abs/1601.01272v2

Details:

Thoughts:
### P-Tree Programming
https://arxiv.org/pdf/1707.03744v1.pdf

Details:

Thoughts:
### Dependency Recurrent Neural Language Models for Sentence Completion
https://arxiv.org/abs/1507.01193v1

Details:

Thoughts:
### Groups convolution
http://colah.github.io/posts/2014-12-Groups-Convolution/

Details:

Thoughts:
### Long Short-Term Memory Over Tree Structures
https://arxiv.org/pdf/1503.04881.pdf

Details:

Thoughts:

